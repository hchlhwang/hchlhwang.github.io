<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> | Hochul Hwang</title> <meta name="author" content="Hochul Hwang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A6%BF&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://hchlhwang.github.io/Eldercare/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Hochul </span>Hwang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/project/">project</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"></h1> <p class="post-description"></p> </header> <article> <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"> <title>Eldercare</title> <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> <style>body{font-family:'Open-Sans',sans-serif;font-weight:300;background-color:#fff}.content{width:1000px;padding:25px 50px;margin:25px auto;background-color:white;box-shadow:0 0 10px #999;border-radius:15px}.contentblock{width:950px;margin:0 auto;padding:0;border-spacing:25px 0}.contentblock td{background-color:#fff;padding:25px 50px;vertical-align:top;box-shadow:0 0 10px #999;border-radius:15px}a,a:visited{color:#224b8d;font-weight:300}#authors{text-align:center;margin-bottom:20px}#conference{text-align:center;margin-bottom:20px;font-style:italic}#authors a{margin:0 10px}h1{text-align:center;font-size:35px;font-weight:300}h2{font-size:30px;font-weight:300}code{display:block;padding:10px;margin:10px 10px}p{line-height:25px;text-align:justify}p code{display:inline;padding:0;margin:0}#teasers{margin:0 auto}#teasers td{margin:0 auto;text-align:center;padding:5px}#teasers img{width:250px}#results img{width:133px}#seeintodark{margin:0 auto}#sift{margin:0 auto}#sift img{width:250px}.downloadpaper{padding-left:20px;float:right;text-align:center}.downloadpaper a{font-weight:bold;text-align:center}#demoframe{border:0;padding:0;margin:0;width:100%;height:340px}#feedbackform{border:1px solid #ccc;margin:0 auto;border-radius:15px}#eyeglass{height:530px}#eyeglass #wrapper{position:relative;height:auto;margin:0 auto;float:left;width:800px}#mitnews{font-weight:normal;margin-top:20px;font-size:14px;width:220px}#mitnews a{font-weight:normal}.teaser-img{width:80%;display:block;margin-left:auto;margin-right:auto}.teaser-gif{display:block;margin-left:auto;margin-right:auto}.summary-img{width:100%;display:block;margin-left:auto;margin-right:auto}.video-iframe{width:1000;height:800;margin:auto;display:block}.container{display:flex;align-items:center;justify-content:center}.image{flex-basis:40%}.text{font-size:20px;padding-left:20px}.center{margin-left:auto;margin-right:auto}.boxshadow{border:1px solid;padding:10px;box-shadow:2px 2px 5px #888}.spacertr{height:8px}.spacertd{width:40px}</style> <div class="content"> <h1>ElderSim: A synthetic data generation platform for human action recognition in eldercare applications</h1> <p id="authors"> <a href="https://hchlhwang.github.io/">Hochul Hwang</a> Cheongjae Jang Geonwoo Park <a href="https://junghyuncho.notion.site/Junghyun-Cho-36f85eff362148dab9e23e6628fe3551" rel="external nofollow noopener" target="_blank">Junghyun Cho</a> <a href="https://sites.google.com/view/ijkim" rel="external nofollow noopener" target="_blank">Ig-Jae Kim</a> <br> Center for Artificial Intelligence @ Korea Institute of Science and Technology <br><i>Access 2020, IEIE 2020</i> </p> <font size="+2"> <p style="text-align: center;"> <a href="https://ieeexplore.ieee.org/abstract/document/9324837" target="_blank" rel="external nofollow noopener">[Paper]</a>      <a href="https://ai4robot.github.io/ElderSim/#" target="_blank" rel="external nofollow noopener">[Project page]</a>      </p> </font> <font size="+1"> </font> <p> <img class="teaser-img" src="/assets/img/elder/har-kist.mp4"> </p> <br> <p id="abstract"><strong>Abstract: </strong> To train deep learning models for vision-based action recognition of elders’ daily activities, we need large-scale activity datasets acquired under various daily living environments and conditions. However, most public datasets used in human action recognition either differ from or have limited coverage of elders’ activities in many aspects, making it challenging to recognize elders’ daily activities well by only utilizing existing datasets. Recently, such limitations of available datasets have actively been compensated by generating synthetic data from realistic simulation environments and using those data to train deep learning models. In this paper, based on these ideas we develop ElderSim, an action simulation platform that can generate synthetic data on elders’ daily activities. For 55 kinds of frequent daily activities of the elders, ElderSim generates realistic motions of synthetic characters with various adjustable data-generating options and provides different output modalities including RGB videos, two- and three-dimensional skeleton trajectories. We then generate KIST SynADL, a large-scale synthetic dataset of elders’ activities of daily living, from ElderSim and use the data in addition to real datasets to train three state-of-the-art human action recognition models. From the experiments following several newly proposed scenarios that assume different real and synthetic dataset configurations for training, we observe a noticeable performance improvement by augmenting our synthetic data. We also offer guidance with insights for the effective utilization of synthetic data to help recognize elders’ daily activities. </p> <br clear="all"> </div> <div class="content" id="synthetic"> <h2 style="text-align:center;">Synthetic data generation</h2> <p style="text-align: center;">The world’s elderly population growth emphasizes the necessity of eldercare technologies and underlines the role of action recognition tasks to comprehend elders’ activities of daily living. However, most public datasets used in human action recognition either differ from or have limited coverage of elders’ activities in many aspects. Moreover, data acquisition of elders’ ADL is challenging due to the privacy and physical limitations of the elderly. We introduce ElderSim, a synthetic action simulation platform that can generate synthetic data on elders’ daily activities. For 55 kinds of frequent daily activities of the elders, ElderSim generates realistic motions of synthetic characters with several customizable data-generating options and provides several output modalities. We also provide KIST SynADL dataset which is generated from our simulation platform. </p> <img class="summary-img" src="/assets/img/elder/summary.png" style="width:80%;"> <img class="summary-img" src="/assets/img/elder/env.png" style="width:50%;"> <br> </div> <div class="content" id="har"> <h2 style="text-align:center;">Human action recognition</h2> <p style="text-align:center;">We experimentally validated the effect of augmenting our synthetic data, KIST SynADL (KIST) for training algorithms to recognize elders' ADL. We begin by introducing two real-world datasets for the experiments and address how insufficient the existing public dataset (NTU RGB+D 120) is to cover the elders' ADL. We then describe three state-of-the-art HAR methods used in the experiments as well as several experimental scenarios to examine the various aspects arising from the recognition of the elders' ADL. Within each experimental scenario, we investigate how our synthetic data can help recognize elders' daily activities and offer some guidance and insights for effective utilization of synthetic data. </p> <center> <img class="summary-img" src="/assets/img/elder/datasets.png" style="width:60%;"> </center> <br> <p style="text-align:center;">We also collected real-world elderly action data to evaluate our synthetic dataset with three different HAR algorithms. </p> <center> <img class="real-img" src="/assets/img/elder/collection.png" style="width:60%;"> </center> <br> <p style="text-align:center;">For the experiments augmenting the KIST SynADL dataset to train ST-GCN and VA-CNN, we balance mini-batches to contain an equal amount of real and synthetic data. Since the sizes of datasets differ, we randomly upsample the dataset of a smaller amount (usually the real-world data) to match the size. Twenty viewpoints of the KIST SynADL dataset were utilized for both methods, while only eight viewpoints were used for the Glimpse method to ensure reasonable training time. We report the results of the experiments performed according to the above settings. In the experiments, we trained three recognition algorithms for the proposed experimental splits and report the average video sequence-level top-1 classification accuracy for the five test trials as the action recognition score. For the results obtained from augmenting the KIST SynADL dataset, we designate the change in the recognition score from that obtained without augmentation in the parenthesis next to the score. For simplicity, I only share the results of the cross-dataset split and the confusion matrix for the cross-subject split. You can find more experimental results in our <a href="https://ieeexplore.ieee.org/abstract/document/9324837" rel="external nofollow noopener" target="_blank">paper</a>. </p> <center> <img class="real-img" src="/assets/img/elder/conf.png" style="width:80%;"> </center> <center> <img class="real-img" src="/assets/img/elder/result.png" style="width:80%;"> </center> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Hochul Hwang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js">MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],processEscapes:!0}};</script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>